{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce96bae",
   "metadata": {},
   "source": [
    "ANS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029d4a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Batch Normalization (BatchNorm or BN) is a technique used in artificial neural networks, primarily deep neural networks, to improve the training process and the overall performance of the model. It involves normalizing the activations of each layer within a mini-batch of data. Here's a detailed explanation of the concept of batch normalization:\\n\\n1. Motivation:\\n\\nIn deep neural networks, especially networks with many layers, the input to each layer can change significantly during training due to weight updates in earlier layers. This phenomenon is known as internal covariate shift. As a result, the network's activations can become skewed, which can lead to vanishing or exploding gradients, slower convergence, and difficulties in training deep networks.\\n\\n2. The Batch Normalization Process:\\n\\nBatch Normalization addresses the issue of internal covariate shift by normalizing the activations of each layer. Here's how it works:\\n\\nFor each mini-batch during training, BatchNorm computes the mean and variance of the activations across the mini-batch.\\n\\nIt then normalizes the activations of each neuron by subtracting the mean and dividing by the standard deviation (with a small epsilon value added for numerical stability).\\n\\nThe normalized activations are then scaled and shifted using learnable parameters (gamma and beta) to allow the network to adapt and learn the most suitable scaling and shifting for each layer.\\n\\n\\nBatch Normalization (BatchNorm) offers several benefits when used during the training of artificial neural networks, especially deep networks. Here are the key advantages of using BatchNorm:\\n\\nAccelerated Training Convergence: BatchNorm speeds up the convergence of training by reducing the impact of the vanishing gradient problem. It allows the use of larger learning rates, which can lead to faster convergence. This means that the model reaches good performance with fewer training iterations.\\n\\nStabilized Learning: By normalizing activations within each layer, BatchNorm reduces the internal covariate shift, which is the change in the distribution of activations due to weight updates in earlier layers. This stabilization helps in training deep networks where layer inputs can become highly skewed.\\n\\nImproved Gradient Flow: BatchNorm helps maintain a more consistent gradient magnitude throughout the training process. This reduces the risk of gradients becoming too small (vanishing gradients) or too large (exploding gradients), making it easier to train very deep networks effectively.\\n\\nReduction in Overfitting: BatchNorm acts as a form of regularization by adding noise to the activations. This stochasticity during training can reduce overfitting and improve the model's generalization performance on unseen data.\\n\\nLess Sensitivity to Weight Initialization: BatchNorm reduces the dependence on choosing the right weight initialization scheme. Even with suboptimal initial weights, BatchNorm can help the network learn effectively by normalizing activations.\\n\\nEfficient Use of Activation Functions: BatchNorm ensures that the activations are within a certain range (usually close to zero mean and unit variance), making it easier for subsequent activation functions like ReLU to operate in their most linear and effective regions. This can lead to improved learning.\\n\\n\\n\\natch Normalization (BatchNorm) is a technique used in neural networks to standardize and normalize the activations within each layer during training. It consists of two main components: the normalization step and learnable parameters. Here's a detailed explanation of how BatchNorm works:\\n\\n1. Normalization Step:\\n\\nThe primary goal of BatchNorm is to ensure that the inputs to each layer in a neural network have a standardized distribution. This is achieved through the following steps within a mini-batch of data during training:\\n\\nStep 1: Compute Mean and Variance:\\n\\nFor each feature (or neuron) in the layer, calculate the mean (\\n\\n ) of the activations across the mini-batch. This is done independently for each feature.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Batch Normalization (BatchNorm or BN) is a technique used in artificial neural networks, primarily deep neural networks, to improve the training process and the overall performance of the model. It involves normalizing the activations of each layer within a mini-batch of data. Here's a detailed explanation of the concept of batch normalization:\n",
    "\n",
    "1. Motivation:\n",
    "\n",
    "In deep neural networks, especially networks with many layers, the input to each layer can change significantly during training due to weight updates in earlier layers. This phenomenon is known as internal covariate shift. As a result, the network's activations can become skewed, which can lead to vanishing or exploding gradients, slower convergence, and difficulties in training deep networks.\n",
    "\n",
    "2. The Batch Normalization Process:\n",
    "\n",
    "Batch Normalization addresses the issue of internal covariate shift by normalizing the activations of each layer. Here's how it works:\n",
    "\n",
    "For each mini-batch during training, BatchNorm computes the mean and variance of the activations across the mini-batch.\n",
    "\n",
    "It then normalizes the activations of each neuron by subtracting the mean and dividing by the standard deviation (with a small epsilon value added for numerical stability).\n",
    "\n",
    "The normalized activations are then scaled and shifted using learnable parameters (gamma and beta) to allow the network to adapt and learn the most suitable scaling and shifting for each layer.\n",
    "\n",
    "\n",
    "Batch Normalization (BatchNorm) offers several benefits when used during the training of artificial neural networks, especially deep networks. Here are the key advantages of using BatchNorm:\n",
    "\n",
    "Accelerated Training Convergence: BatchNorm speeds up the convergence of training by reducing the impact of the vanishing gradient problem. It allows the use of larger learning rates, which can lead to faster convergence. This means that the model reaches good performance with fewer training iterations.\n",
    "\n",
    "Stabilized Learning: By normalizing activations within each layer, BatchNorm reduces the internal covariate shift, which is the change in the distribution of activations due to weight updates in earlier layers. This stabilization helps in training deep networks where layer inputs can become highly skewed.\n",
    "\n",
    "Improved Gradient Flow: BatchNorm helps maintain a more consistent gradient magnitude throughout the training process. This reduces the risk of gradients becoming too small (vanishing gradients) or too large (exploding gradients), making it easier to train very deep networks effectively.\n",
    "\n",
    "Reduction in Overfitting: BatchNorm acts as a form of regularization by adding noise to the activations. This stochasticity during training can reduce overfitting and improve the model's generalization performance on unseen data.\n",
    "\n",
    "Less Sensitivity to Weight Initialization: BatchNorm reduces the dependence on choosing the right weight initialization scheme. Even with suboptimal initial weights, BatchNorm can help the network learn effectively by normalizing activations.\n",
    "\n",
    "Efficient Use of Activation Functions: BatchNorm ensures that the activations are within a certain range (usually close to zero mean and unit variance), making it easier for subsequent activation functions like ReLU to operate in their most linear and effective regions. This can lead to improved learning.\n",
    "\n",
    "\n",
    "\n",
    "atch Normalization (BatchNorm) is a technique used in neural networks to standardize and normalize the activations within each layer during training. It consists of two main components: the normalization step and learnable parameters. Here's a detailed explanation of how BatchNorm works:\n",
    "\n",
    "1. Normalization Step:\n",
    "\n",
    "The primary goal of BatchNorm is to ensure that the inputs to each layer in a neural network have a standardized distribution. This is achieved through the following steps within a mini-batch of data during training:\n",
    "\n",
    "Step 1: Compute Mean and Variance:\n",
    "\n",
    "For each feature (or neuron) in the layer, calculate the mean (\n",
    "\n",
    " ) of the activations across the mini-batch. This is done independently for each feature.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9a4b3",
   "metadata": {},
   "source": [
    "ANS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "651792a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.0 (from versions: 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.14.0rc0, 2.14.0rc1)\n",
      "ERROR: No matching distribution found for tensorflow==2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc599237",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)  # One-hot encode labels\n",
    "\n",
    "# Model without batch normalization\n",
    "model_without_bn = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model without batch normalization\n",
    "model_without_bn.compile(optimizer='adam',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "# Model with batch normalization\n",
    "model_with_bn = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with batch normalization\n",
    "model_with_bn.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train both models\n",
    "epochs = 5\n",
    "history_without_bn = model_without_bn.fit(x_train, y_train, epochs=epochs, validation_split=0.2, verbose=0)\n",
    "history_with_bn = model_with_bn.fit(x_train, y_train, epochs=epochs, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate both models on the test dataset\n",
    "test_loss_without_bn, test_acc_without_bn = model_without_bn.evaluate(x_test, y_test)\n",
    "test_loss_with_bn, test_acc_with_bn = model_with_bn.evaluate(x_test, y_test)\n",
    "\n",
    "# Print test accuracy\n",
    "print(\"Test accuracy without batch normalization:\", test_acc_without_bn)\n",
    "print(\"Test accuracy with batch normalization:\", test_acc_with_bn)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_without_bn.history['accuracy'], label='Train Accuracy (No BN)')\n",
    "plt.plot(history_without_bn.history['val_accuracy'], label='Validation Accuracy (No BN)')\n",
    "plt.title('Model Performance Without Batch Normalization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_with_bn.history['accuracy'], label='Train Accuracy (With BN)')\n",
    "plt.plot(history_with_bn.history['val_accuracy'], label='Validation Accuracy (With BN)')\n",
    "plt.title('Model Performance With Batch Normalization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a865286d",
   "metadata": {},
   "source": [
    "ANS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421238b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to [0, 1]\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)  # One-hot encode labels\n",
    "\n",
    "# Batch sizes to experiment with\n",
    "batch_sizes = [32, 128, 512]\n",
    "\n",
    "# Lists to store training history for each batch size\n",
    "histories = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    # Build the neural network model with batch normalization\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with the current batch size\n",
    "    history = model.fit(x_train, y_train, epochs=5, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    histories.append(history)\n",
    "\n",
    "# Evaluate and compare models on the test dataset\n",
    "test_accuracies = []\n",
    "for model in models:\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "# Print test accuracies for each batch size\n",
    "for i, batch_size in enumerate(batch_sizes):\n",
    "    print(f\"Test accuracy (Batch Size {batch_size}): {test_accuracies[i]:.4f}\")\n",
    "\n",
    "# Plot training and validation accuracy for each batch size\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, history in enumerate(histories):\n",
    "    plt.subplot(1, len(batch_sizes), i + 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Model Performance (Batch Size {batch_sizes[i]})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"  Batch Normalization (BatchNorm) is a powerful technique in improving the training of neural networks, but it comes with its own advantages and limitations. Let's discuss both:\n",
    "\n",
    "Advantages of Batch Normalization:\n",
    "\n",
    "Stabilized Training: BatchNorm reduces internal covariate shift by normalizing activations within each layer during training. This stabilizes the training process, allowing for faster and more stable convergence of the network.\n",
    "\n",
    "Faster Convergence: With BatchNorm, networks often converge faster because it mitigates issues like vanishing gradients and enables the use of larger learning rates. This can significantly reduce the time required for training.\n",
    "\n",
    "Improved Gradient Flow: BatchNorm ensures that activations have consistent magnitudes, which helps in maintaining a healthy gradient flow throughout the network. This reduces the likelihood of vanishing or exploding gradients.\n",
    "\n",
    "Regularization Effect: BatchNorm introduces a degree of noise in the form of mini-batch statistics during training. This acts as a form of regularization, reducing overfitting and improving generalization.\n",
    "\n",
    "Reduced Sensitivity to Weight Initialization: Neural networks with BatchNorm are often less sensitive to the choice of weight initialization, making it easier to train effectively.\n",
    "\n",
    "Efficient Training of Deep Networks: BatchNorm is particularly valuable in training very deep networks, such as deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs), where gradient issues are more pronounced.\n",
    "\n",
    "Compatibility with Various Architectures: BatchNorm can be applied to different types of neural network architectures, making it a versatile tool in deep learning.\n",
    "\n",
    "Limitations and Considerations:\n",
    "\n",
    "Increased Computational Cost: BatchNorm introduces additional computations during both training and inference. While modern hardware can handle this, it can still increase the training time and memory requirements.\n",
    "\n",
    "Batch Size Dependency: BatchNorm computes statistics within mini-batches. Very small batch sizes can lead to inaccurate estimates of mean and variance, potentially affecting training stability. Larger batch sizes can reduce the regularization effect of BatchNorm.\n",
    "\n",
    "Not Always Beneficial: While BatchNorm is generally beneficial, there are cases where it might not lead to significant improvements, or it may even degrade performance. Careful experimentation is needed to determine when and where to apply it.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefff749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
